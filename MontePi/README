Compile with

    mvn package

Run with

    $SPARK_HOME/bin/spark-submit --class JavaSparkPi build/JavaSparkPi-1.0.jar


startSpark --time=15:00:00 --nodes=2 --partition=gpu2 --cpus-per-task=2 --gres='gpu:2'
makeOptsSpark=(                                                      \
    "SPARK_ROOT=$HOME/spark-1.5.2-bin-hadoop2.6"                     \
    "SPARK_JAR=$SPARK_ROOT/lib/spark-assembly-1.5.2-hadoop2.6.0.jar" \    
    "SPARKCORE_JAR=$SPARK_JAR"                                       \
    "SCALA_ROOT=$(dirname $(which scala))/../lib"                    \
)
folder=$HOME/scaromare/MontePi/multiNode/multiGpu/scala
make -C "$folder" -B ${makeOptsSpark[@]} MontePi.jar
sparkSubmit "$folder/MontePi.jar" 268435456 2 2 2>&1 | sed '/ INFO /d'

    Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
    16/07/29 01:03:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
    16/07/29 01:03:56 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
    Found these hosts with each these number of GPUs : 
        taurusi2094 : 2 (43849.728GFlops)
    Found 2 GPUs in total.
    GPUs per host actually to be used : 
        (taurusi2094,4.3849728E13) : 2
    0
    These are the seed ranges for each partition of MonteCarloPi:
        0 -> (7135068,4611686018434522971)
        1 -> (4611686018434522971,7135065)
    16/07/29 01:04:03 WARN TaskSetManager: Lost task 1.0 in stage 12.0 (TID 18, 172.24.36.103): java.lang.ClassCastException: MonteCarloPiKernel cannot be cast to [J
        at MonteCarloPiKernel.org_trifort_readFromHeapRefFields_MonteCarloPiKernel0(Jasmin)
        at MonteCarloPiKernelSerializer.doReadFromHeap(Jasmin)
        at org.trifort.rootbeer.runtime.Serializer.readFromHeap(Serializer.java:155)
        at org.trifort.rootbeer.runtime.CUDAContext.readBlocksList(CUDAContext.java:452)
        at org.trifort.rootbeer.runtime.CUDAContext$GpuEventHandler.onEvent(CUDAContext.java:332)
        at org.trifort.rootbeer.runtime.CUDAContext$GpuEventHandler.onEvent(CUDAContext.java:308)
        at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:724)

    Results per Slice : 
        [taurusi2094, Rank 0, GPU 0] 134217728 iterations -> pi = 3.1317039132118225
        [taurusi2094, Rank 1, GPU 0] 134217728 iterations -> pi = 3.1383594274520874

    Using 2 slices and 2 GPUs. Rolling the dice 268435456 times resulted in pi ~ 3.135031670331955 and took 4.549351536 seconds

