
Compiling https://github.com/pcpratts/rootbeer1 on my home Linux:
    sudo apt-get install -t stretch openjdk-8-jdk
    export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
    cd "/media/d/Studium/9TH SEMESTER/Hauptseminar CUDA on Sparc/rootbeer1"
    ant jar && ./pack-rootbeer
    # ant is a java base make tool
    $JAVA_HOME/bin/java -jar Rootbeer.jar -norecursion -nodoubles -runeasytests
        caching package names for: /media/d/Studium/9TH SEMESTER/Hauptseminar CUDA on Sparc/rootbeer1/Rootbeer.jar
        caching package names for: /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar
        cpool == null
        java.lang.NullPointerException
            at soot.rbclassload.RootbeerClassLoader.loadHierarchySootClasses(RootbeerClassLoader.java:963)
            at soot.rbclassload.RootbeerClassLoader.loadNecessaryClasses(RootbeerClassLoader.java:294)
            at org.trifort.rootbeer.entry.RootbeerCompiler.setupSoot(RootbeerCompiler.java:198)
            at org.trifort.rootbeer.entry.RootbeerCompiler.compile(RootbeerCompiler.java:219)
            at org.trifort.rootbeer.entry.RootbeerCompiler.compile(RootbeerCompiler.java:213)
            at org.trifort.rootbeer.entry.Main.run(Main.java:208)
            at org.trifort.rootbeer.entry.Main.main(Main.java:244)
        caching package names for: dist/ScalarAddApp.jar
        remapping class: java.util.concurrent.atomic.AtomicLong
        java.lang.NullPointerException
            at soot.rbclassload.RootbeerClassLoader.remapClasses(RootbeerClassLoader.java:998)
            at soot.rbclassload.RootbeerClassLoader.loadNecessaryClasses(RootbeerClassLoader.java:295)
            at org.trifort.rootbeer.entry.RootbeerCompiler.setupSoot(RootbeerCompiler.java:198)
            at org.trifort.rootbeer.entry.RootbeerCompiler.compile(RootbeerCompiler.java:219)
            at org.trifort.rootbeer.entry.RootbeerCompiler.compile(RootbeerCompiler.java:213)
            at org.trifort.rootbeer.entry.Main.run(Main.java:208)
            at org.trifort.rootbeer.entry.Main.main(Main.java:244)
    cd examples/ScalarAddApp/
    ant jar
    $JAVA_HOME/bin/java -jar ../../Rootbeer.jar dist/ScalarAddApp.jar dist/ScalarAddApp-GPU.jar -64bit
        https://github.com/pcpratts/rootbeer1/issues/175
      => only works fully with Java 6 -.-.... Java 7 may also work -> trying with 7, because 6 is not in repository

    sudo apt-get install -t stretch openjdk-7-jdk
    export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
    ant clean && ant jar && ./pack-rootbeer && cd examples/ScalarAddApp/ && ant jar
    java -jar ../../Rootbeer.jar dist/ScalarAddApp.jar dist/ScalarAddApp-GPU.jar -64bit
        warning: sm_12 and sm_11 not supported with recursion. use -norecursion to enable.
        warning: sm_12 and sm_11 not supported with doubles. use -nodoubles to enable.
        [...]
        compiling CUDA code for 64bit only...
        In file included from /usr/local/cuda/include/cuda_runtime.h:62:0,
                         from <command-line>:0:
        /usr/local/cuda/include/host_config.h:105:2: error: #error -- unsupported GNU version! gcc 4.10 and up are not supported!
         #error -- unsupported GNU version! gcc 4.10 and up are not supported!
          ^
    http://lektiondestages.blogspot.de/2013/05/installing-and-switching-gccg-versions.html
        update-alternatives --display gcc
        update-alternatives --display g++
            update-alternatives: error: no alternatives for gcc
            update-alternatives: error: no alternatives for g++

        # --install <link> <name> <path> <priority> [--slave <link> <name> <path>] ...
        # when the master is changed, any associated slaves are changed too.  A master link and its associated slaves make up a link group.

        sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5   60 --slave /usr/bin/g++ g++ /usr/bin/g++-5
        sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.9 40 --slave /usr/bin/g++ g++ /usr/bin/g++-4.9
            update-alternatives: using /usr/bin/gcc-5 to provide /usr/bin/gcc (gcc) in auto mode

        sudo update-alternatives --config gcc

    java -jar ../../Rootbeer.jar -norecursion -nodoubles dist/ScalarAddApp.jar dist/ScalarAddApp-GPU.jar -64bit
        nvcc fatal   : Unsupported gpu architecture 'compute_12'
    /opt/cuda-7.0/samples/1_Utilities/deviceQuery/deviceQuery
        /opt/cuda-7.0/samples/1_Utilities/deviceQuery/deviceQuery Starting...

         CUDA Device Query (Runtime API) version (CUDART static linking)

        Detected 1 CUDA Capable device(s)

        Device 0: "GeForce GTX 760"
          CUDA Driver Version / Runtime Version          7.5 / 7.0
          CUDA Capability Major/Minor version number:    3.0
          Total amount of global memory:                 2040 MBytes (2138861568 bytes)
          ( 6) Multiprocessors, (192) CUDA Cores/MP:     1152 CUDA Cores
          GPU Max Clock rate:                            1150 MHz (1.15 GHz)
          Memory Clock rate:                             3004 Mhz
          Memory Bus Width:                              256-bit
          L2 Cache Size:                                 524288 bytes
          Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)
          Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers
          Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers
          Total amount of constant memory:               65536 bytes
          Total amount of shared memory per block:       49152 bytes
          Total number of registers available per block: 65536
          Warp size:                                     32
          Maximum number of threads per multiprocessor:  2048
          Maximum number of threads per block:           1024
          Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
          Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
          Maximum memory pitch:                          2147483647 bytes
          Texture alignment:                             512 bytes
          Concurrent copy and kernel execution:          Yes with 1 copy engine(s)
          Run time limit on kernels:                     Yes
          Integrated GPU sharing Host Memory:            No
          Support host page-locked memory mapping:       Yes
          Alignment requirement for Surfaces:            Yes
          Device has ECC support:                        Disabled
          Device supports Unified Addressing (UVA):      Yes
          Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0
          Compute Mode:
             < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >

        deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 7.5, CUDA Runtime Version = 7.0, NumDevs = 1, Device0 = GeForce GTX 760
        Result = PASS

        java -jar ../../Rootbeer.jar dist/ScalarAddApp.jar dist/ScalarAddApp-GPU.jar -64bit -computecapability=sm_30
        ./dist/ScalarAddApp-GPU.jar

Compile MergeSort:
    cd MergeSort
    rm *.class; javac *.java && java TestMergeSort
    jar -cf TestMergeSort.jar *.class
    ./TestMergeSort
        no main manifest attribute, in TestMergeSort.jar
    jar -tf TestMergeSort.jar META-INF/MANIFEST.MF
    echo 'Main-Class: TestMergeSort' > META-INF/MANIFEST.MF
    jar -cf TestMergeSort.jar META-INF/MANIFEST.MF *.class

    rm *.class; javac *.java && jar -cvfm TestMergeSort.jar manifest.txt MergeSort.class TestMergeSort.class && java -jar ./TestMergeSort.jar
        => works (no package line specified in java files!)

Compile MergeSort with Rootbeer:
    cd MergeSortGPU
    rm *.class; javac *.java && jar -cvfm TestMergeSort.jar manifest.txt MergeSort.class TestMergeSort.class


Problem with MonteCarloPi with 1e8 rolls (watchdog?):
    ./TestMontePiGPU.jar
    Run tasks with length 1024

    Exception in thread "main" org.trifort.rootbeer.runtime.CudaErrorException: ERROR STATUS:702 : Error in cuCtxSynchronize
        at org.trifort.rootbeer.runtime.CUDAContext.cudaRun(Native Method)
        at org.trifort.rootbeer.runtime.CUDAContext.runGpu(CUDAContext.java:388)
        at org.trifort.rootbeer.runtime.CUDAContext.access$1300(CUDAContext.java:17)
        at org.trifort.rootbeer.runtime.CUDAContext$GpuEventHandler.onEvent(CUDAContext.java:331)
        at org.trifort.rootbeer.runtime.CUDAContext$GpuEventHandler.onEvent(CUDAContext.java:308)
        at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)

when trying to write everything in scala:
    java.lang.RuntimeException: cannot get resident body for phantom class : <MonteCarloPi$$anonfun$calc$2: java.lang.Object apply(java.lang.Object)>; maybe you want to call c.setApplicationClass() on this class!
	at soot.SootMethod.retrieveActiveBody(SootMethod.java:316)
	at soot.rbclassload.RootbeerClassLoader.loadScene(RootbeerClassLoader.java:857)
	at soot.rbclassload.RootbeerClassLoader.loadNecessaryClasses(RootbeerClassLoader.java:320)
	at org.trifort.rootbeer.entry.RootbeerCompiler.setupSoot(RootbeerCompiler.java:198)
	at org.trifort.rootbeer.entry.RootbeerCompiler.compile(RootbeerCompiler.java:219)
	at org.trifort.rootbeer.entry.RootbeerCompiler.compile(RootbeerCompiler.java:213)
	at org.trifort.rootbeer.entry.Main.run(Main.java:208)
	at org.trifort.rootbeer.entry.Main.main(Main.java:244)


Install and use spark:
    wget ...
    tar -xf spark-1.5.2.tgz
    cd spark-1.5.2
    build/mvn -DskipTests clean package
    /opt/spark-1.5.2/bin/spark-shell --master local[2]
    # quelch some warnings with:
    export SPARK_LOCAL_IP=127.0.0.1

    Scala compiles, but throws error with spark-submit ... -.-
        Exception in thread "main" java.lang.NoSuchMethodError: scala.runtime.ObjectRef.create(Ljava/lang/Object;)Lscala/runtime/ObjectRef;
      -> install scala 2.10 http://www.scala-lang.org/download/install.html
         because only 2.9 and 2.11 seem to be in the debian repositories

Scala GPU:
  - ScalaCL ( "ScalaCL is not production-ready!" )
  - BIDMach
  - Firepile
  - Rootbeer


Run on Taurus:
    module load java/jdk1.7.0_25 scala/2.10.4 cuda/7.0.28

    salloc -p gpu-interactive --nodes=1 --gres=gpu:2 --time=1:30:00
    Taurus does not have anything -.-.... maven, ant, spark ... need to do everything manually:
    ant:
        tar -xf apache-ant-1.9.6-src.tar.bz2
        cd apache-ant-1.9.6
        sh build.sh -Ddist.dir=$HOME/programs/ dist
    rootbeer1:
        ant jar
        ./pack-rootbeer
    zipmerge
        wget http://www.nih.at/libzip/libzip-1.0.1.tar.xz
        tar -xf libzip-1.0.1.tar.xz
        cd libzip-1.0.1
        ./configure --prefix=$HOME/programs/ && make install

    export PATH="$PATH:$HOME/spark-1.5.2-bin-hadoop2.6/bin/:$HOME/spark-1.5.2-bin-hadoop2.6/sbin/"

    single GPU on Taurus:
        cd $HOME/scaromare/MontePi/singleNode/singleGpu/scala
        make SPARK_ROOT=~/spark-1.5.2-bin-hadoop2.6 SPARKCORE_JAR=~/spark-1.5.2-bin-hadoop2.6/lib/spark-assembly-1.5.2-hadoop2.6.0.jar SCALA_ROOT=$(dirname $(which scala))/../lib MontePiGPU.jar
        srun -n1 scala MontePiGPU.jar 268435456

    multicore spark on Taurus:
        salloc -p gpu-interactive --nodes=1 --ntasks-per-node=4 --cpus-per-task=1 --gres=gpu:2 --time=1:30:00
        cd $HOME/scaromare/MontePi/multiNode/multiCore
        make SPARK_ROOT=~/spark-1.5.2-bin-hadoop2.6 SPARKCORE_JAR=~/spark-1.5.2-bin-hadoop2.6/lib/spark-assembly-1.5.2-hadoop2.6.0.jar SCALA_ROOT=$(dirname $(which scala))/../lib MontePi.jar
        spark-submit --total-executor-cores 4 --class TestMonteCarloPi MontePi.jar 268435456 4

    a cleaner version:
        salloc --time 00:30:00 --mem=512 --ntasks=1 --cpus-per-task=1 $HOME/spark-1.5.2-bin-hadoop2.6/sbin/start-master.sh
        cat $HOME/spark-1.5.2-bin-hadoop2.6/logs/spark-$USER-org.apache.spark.deploy.master.Master-1-tauruslogin4.out
        salloc --time 00:30:00 --nodes=4 --ntasks=1 --cpus-per-task=1 --gres=gpu:1 $HOME/spark-1.5.2-bin-hadoop2.6/sbin/start-slave.sh spark://taurusi2108:7077
        # when the above is run with srun instead the following error occurs:
            failed to launch org.apache.spark.deploy.master.Master:
            full log in $HOME/spark-1.5.2-bin-hadoop2.6/sbin/../logs/spark-$USER-org.apache.spark.deploy.master.Master-1-tauruslogin4.out

        srun --time 00:30:00 --mem=1024 --ntasks=1 --cpus-per-task=1 start-master.sh
        spark-submit --total-executor-cores 1 --class TestMonteCarloPi MontePi.jar 268435456 1
        srun --time 00:30:00 --mem=1024 --ntasks=1 --cpus-per-task=1


    ==========
    sbatch --time 00:30:00 --mem=512 --ntasks=1 --cpus-per-task=1 <<EOF
#!/bin/bash
start-master
EOF

    ==========
    salloc -p gpu-interactive --nodes=2 --ntasks-per-node=1 --cpus-per-task=1 --gres=gpu:1 --time=00:30:00
    start-master.sh
    srun start-slave.sh spark://tauruslogin4:7077 &


    multi GPU:
        cd ~/scaromare/MontePi/multiNode/multiGpu/scala
        make SPARK_ROOT=~/spark-1.5.2-bin-hadoop2.6 SPARKCORE_JAR=~/spark-1.5.2-bin-hadoop2.6/lib/spark-assembly-1.5.2-hadoop2.6.0.jar SCALA_ROOT=$(dirname $(which scala))/../lib




Compile Spark on Taurus gives:
    "Failed to execute goal net.alchim31.maven:scala-maven-plugin:3.2.2:testCompile (scala-test-compile-first) on project spark-core_2.10: Execution scala-test-compile-first of goal net.alchim31.maven:scala-maven-plugin:3.2.2:testCompile failed. CompileFailed"
    http://stackoverflow.com/questions/31844848/building-spark-with-maven-error-finding-javac-but-path-is-correct
      - installed binaries ...

Count most frequent words:
    /opt/spark-1.5.2/bin/spark-shell --master local[2]
    sc.hadoopConfiguration.set( "mapreduce.input.fileinputformat.input.dir.recursive", "true" )
    sc.hadoopConfiguration.get( "mapreduce.input.fileinputformat.input.dir.recursive" )
    var textFiles = sc.textFile("./*")
    textFiles.first()
    textFiles.take(10)
    textFiles.take(20).drop(10)
    val wordCounts = textFiles.flatMap( line => line.split(" ") ).map( word => (word, 1) ).reduceByKey( (a, b) => a + b ).sortBy( _._2, false /*descending*/ )

    sc.textFile("./*").flatMap( line => line.split(" ") ).map( word => (word, 1) ).reduceByKey( (a, b) => a + b ).sortBy( _._2, false /*descending*/ ).take(500).foreach( println )


Getting Multi-GPU to work:
    grep -r 'setThreadConfig' ../../scaromare/rootbeer1/


Bugfixing Rootbeer 8192 error:
    BlockShaper.java:
        int max_blocks = getMaxThreads(num_processors);
        // ... bitch pleeeeeaaasse

Fixing Multi-GPU in Rootbeer -.-

    public void run(List<Kernel> work)
    {
        Context context = createDefaultContext();
        ThreadConfig thread_config = getThreadConfig(work, context.getDevice());
        try
        {
            context.setThreadConfig(thread_config);
            context.setKernel(work.get(0));
            context.setUsingHandles(true);
            context.buildState();
            context.run(work);
        }
        finally
        {
            context.close();
        }
    }

    public Context createDefaultContext()
    {
        List<GpuDevice> devices = getDevices();
        GpuDevice best = null;
        for(GpuDevice device : devices)
        {
            if( best == null or device.getMultiProcessorCount() > best.getMultiProcessorCount() )
                best = device;
        }
        if(best == null)
            return null;
        else
          return best.createContext();
    }


    3.) Rootbeer constructor
    3.1.) CUDALoader constructor
    3.2.) CUDALoader.load
          Load shared libraries with fixed absolute paths mostly ...
              m_libCudas.add("/usr/lib64/libcuda.so");
              m_libCudas.add("/usr/lib/x86_64-linux-gnu/libcudart.so.5.0");
              m_rootbeerRuntimes.add(RootbeerPaths.v().getRootbeerHome()+"rootbeer_x64.so.1");
              m_rootbeerCudas.add(RootbeerPaths.v().getRootbeerHome()+"rootbeer_cuda_x64.so.1");
    4.) Rootbeer.getDevices
          Class c = Class.forName("org.trifort.rootbeer.runtime.CUDARuntime");
          Constructor<IRuntime> ctor = c.getConstructor();
          m_cudaRuntime = ctor.newInstance();
          m_cards.addAll( m_cudaRuntime.getGpuDevices() );
    4.1.) CUDA_Runtime.c
            status = cuDeviceGet(&device, i);
            cuDeviceGetAttribute(...)
            [...]
    5.) GPUDevice.createContext -> CUDAContext -> native initializeDriver
            https://de.wikipedia.org/wiki/Java_Native_Interface
        ./csrc/org/trifort/rootbeer/runtime/CUDAContext.c:JNIEXPORT void JNICALL Java_org_trifort_rootbeer_runtime_CUDAContext_initializeDriver
            only saves function pointers to context.java
    6.) Rootber.run
    6.1.) Context context = createDefaultContext(); // skipped for multi-GPU
    6.2.) context.setThreadConfig(thread_config);
    6.3.) context.setKernel(work.get(0));
    6.4.) context.setUsingHandles(true);
    6.5.) context.buildState();
            gpuEvent.setValue(GpuEventCommand.NATIVE_BUILD_STATE);
                GpuEventHandler.onEvent
                    nativeBuildState( ..., gpuDevice.getDeviceId(), ... )
                        Java_org_trifort_rootbeer_runtime_CUDAContext_nativeBuildState in CUDAContext.c
    6.6.) context.run(work)
            context.runAsync(work)
                gpuEvent.setValue(GpuEventCommand.NATIVE_RUN_LIST);
                    GpuEventHandler.onEvent
                        writeBlocksTemplate();
                        runGpu();
                            cudaRun(nativeContext, objectMemory, b2i(!usingHandles), stats);
                        readBlocksTemplate();
          private native void cudaRun(long nativeContext, Memory objectMem, int usingKernelTemplates, StatsRow stats);



    Make change in CUDAContext.c
    /rootbeer1/csrc$ ./compile_linux_x64
    rootbeer1$ ant jar && ./pack-rootbeer

Using nvvp:
    srun -p gpu-interactive --nodes=1 --ntasks-per-node=1 --cpus-per-task=1 --gres=gpu:2 --time=1:30:00 --mem-per-cpu=6000 --x11=first nvvp
    Executable: /sw/global/tools/java/jdk1.7.0_25/bin/java
    Working Directory: ...
    Arguments: -jar ./MontePi.jar 2684354560
       -> works :3

Rootbeer-Paper:
        1) serialize state to GPU memory
        2) define the kernel code that the GPU will execute
        3) control the kernel
        4) deserialize state back to CPU memory
      -> "serialize"?
      => Rootbeer does these things automatically in contrast to CUDA- and OpenCL- Java language bindings
      supports:
        1) single and multi-dimensional arrays of primitive and reference types
        2) composite objects
        3) instance and static fields
        4) dynamic memory allocation
        5) inner classes
        6) synchronized methods and monitors
        7) strings
        8) exceptions that are thrown or caught on the GPU
    Introduction
      - focus on NVidia because of recursion
      - Without Rootbeer, using Java language bindings, a developer must carefully convert complex graphs of Java objects into arrays of basic types.
      - Without Rootbeer, a developer must write separate code in another language to specify what the GPU execution will do
      - Rootbeer also has a native debugging mode where the GPU code is executed on a multi-core CPU inside a C++ debugger.
    Programming Interface:
        public interface Kernel {
            void gpuMethod();
        }
      - get data onto GPU by settings private members
      - byte code from gpuMethod is cross-compiled with CUDA
        List<Kernel> jobs = new ArrayList<Kernel>();
        int[] ret = new int[ arrays.size() ];
        for( int i = 0; i < arrays.size(); ++i )
        {
            jobs.add( new ArraySum( arrays.get(i), ret, i ) );
        }
        Rootbeer rootbeer = new Rootbeer();
        rootbeer.runAll(jobs);
      - compile to jar
      - run Rootbeer on jar
        java -jar Rootbeer.jar InputJar.jar OutputJar.jar
    High Level Processing Overview:
      - jar -[extract]-> .class
            -[read with Soot]-> Jimple:
         . search for Kernel implementations
         . find all types, methods, fields meant for GPU
            -[generated CUDA code]-> .cu
            -[call nvcc]-> .cubin
         . Generate byte code for serialization
         . insert compiled interface which serialzes and calls cubin
           -> convert back to bytecode
        -[pack into jar]-> jar
    High Performance (De)Serialization in Java
        1) Java Native interface (JNI)  247 ms
        2) Reflection                   173 ms
        3) Purve Java                     5 ms
      - "custom Java Bytecode that reads fields and places the results into a Java byte array"
          -> scheint komplett zerstreut im Speicher zu liegen ...
       -> JNI call cudaMemcpy
    Representing Java Objects on the GPU
      - static + instance memory
         |              |
         + simple C-Array with differing offsets (must be primitive type)
                        +
            set of object with 16B header:
                Reserved for Garbage Collector 10 bytes (future work)
                Derived Type                    1 byte
                Created on GPU flag             1 byte  (malloc from kernel)
                Object Monitor State            4 bytes
    CUDA Code Generation:
      - Future: better serialization + shared memory
    Related Work:
      - jCUDA, jocl, JavaCL -> require serialization of object graphs to primitive arrays
      - JikesRVM to auto-detect parallelism runtime
      - Peter Calvert’s annotations like OpenMP -> not well-working for all cases ...
      Aparapi very similar, but less full-featured

2016-05-01:
jar -cvf MontePiGPUtmp.jar MonteCarloPi.class

java -jar ../../../../rootbeer1/Rootbeer.jar MontePiGPUtmp.jar MontePiGPU.jar -64bit -computecapability=sm_30

jar -cvfm MontePiGPU.jar.tmp manifest.txt DummyEntry.class MonteCarloPiKernel.class MonteCarloPi.class TestMonteCarloPi.class 'TestMonteCarloPi$.class' &&
zipinfo MontePiGPU.jar.tmp &&
#zipmerge MontePiGPU.jar.merged /usr/share/java/scala-library.jar MontePiGPU.jar.tmp &&
java -jar "$ROOTBEER_ROOT"/Rootbeer.jar MontePiGPU.jar.tmp MontePiGPU.jar -64bit -computecapability=sm_30

#Warning: the following soot-classpath entry is not a supported archive file (must be .zip, .jar or .apk): MontePiGPU.jar.tmp


	jar -cfm rest.jar manifest.txt TestMonteCarloPi*.class MonteCarloPi.class
	zipmerge merged.jar "$SCALA_JAR" MontePiGPU.jar rest.jar
	java -jar merged.jar


# (1) Gives error, because of Soot clashing with scala?
jar -cfm tmp.jar manifest.txt MonteCarloPiKernel.class MonteCarloPi*.class TestMonteCarloPi*.class &&
zipmerge merged.jar "$SCALA_JAR" tmp.jar &&
java -jar "$ROOTBEER_ROOT"/Rootbeer.jar merged.jar MontePi.jar -64bit -computecapability=sm_30 &&
java -jar MontePi.jar
# (2) this instead works fine:
jar -cf tmp.jar MonteCarloPiKernel.class &&
java -jar "$ROOTBEER_ROOT"/Rootbeer.jar tmp.jar gpu.jar -64bit -computecapability=sm_30 &&
jar -cfm nongpu.jar manifest.txt TestMonteCarloPi*.class MonteCarloPi.class &&
zipmerge MontePi.jar "$SCALA_JAR" gpu.jar nongpu.jar &&
java -jar MontePi.jar
# (3) but again this doesn't -.-
jar -cfm tmp.jar manifest.txt MonteCarloPiKernel.class MonteCarloPi*.class &&
java -jar "$ROOTBEER_ROOT"/Rootbeer.jar tmp.jar gpu.jar -64bit -computecapability=sm_30 &&
zipmerge MontePi.jar "$SCALA_JAR" gpu.jar &&
zip -u MontePi.jar TestMonteCarloPi*.class &&
java -jar MontePi.jar
# (1) Exception in thread "main" java.lang.NullPointerException
# 	at scala.io.StdIn$class.readLine(Jasmin)
# 	at scala.io.StdIn$.readLine(Jasmin)
# 	at scala.io.StdIn$class.readInt(Jasmin)
# 	at scala.io.StdIn$.readInt(Jasmin)
# 	at TestMonteCarloPi$.main(Jasmin)
# 	at TestMonteCarloPi.main(Jasmin)

# (4) this also works fine:
jar -cfm tmp.jar manifest.txt MonteCarloPiKernel.class MonteCarloPi.class &&
java -jar "$ROOTBEER_ROOT"/Rootbeer.jar tmp.jar gpu.jar -64bit -computecapability=sm_30 &&
jar -cf nongpu.jar TestMonteCarloPi*.class &&
zipmerge MontePi.jar "$SCALA_JAR" gpu.jar nongpu.jar &&
java -jar MontePi.jar

# (5)
# Exception in thread "main" java.lang.ClassCastException: MonteCarloPiKernel cannot be cast to org.trifort.rootbeer.runtime.CompiledKernel
# 	at org.trifort.rootbeer.runtime.CUDAContext.setKernel(CUDAContext.java:119)
# 	at MonteCarloPi.runOnDevice(MonteCarloPi.java:116)
# 	at MonteCarloPi.calc(MonteCarloPi.java:180)
# 	at TestMonteCarloPi$.main(TestMonteCarloPi.scala:75)
# 	at TestMonteCarloPi.main(TestMonteCarloPi.scala)
jar -cf tmp.jar MonteCarloPiKernel.class &&
java -jar "$ROOTBEER_ROOT"/Rootbeer.jar tmp.jar gpu.jar -64bit -computecapability=sm_30 &&
jar -cfm nongpu.jar manifest.txt TestMonteCarloPi*.class MonteCarloPi.class &&
zipmerge MontePi.jar "$SCALA_JAR" gpu.jar nongpu.jar &&
java -jar MontePi.jar

what was -deprecation flag for?
pdfs Nico
